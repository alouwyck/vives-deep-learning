{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAuFyjHkAnF8XiXG9csCJF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alouwyck/vives-deep-learning/blob/main/topic3/Chollet_HFST3_no_solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p34cmLp6FrA6"
      },
      "source": [
        "<img src=\"data:image/png;base64,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\" align=\"right\" /><br>\n",
        "\n",
        "\n",
        "**DEEP LEARNING**<br>\n",
        "Academiejaar 2022-2023<br>\n",
        "Andy Louwyck\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Introduction to Keras and TensorFlow**"
      ],
      "metadata": {
        "id": "iLCSjMEqcv1u"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRxs4lx2Ap12"
      },
      "source": [
        "Deze notebook bevat de codevoorbeelden van paragrafen 3.5 en 3.6 uit hoofdstuk 3 van het boek \"Deep Learning with Python\" (2e editie) van François Chollet."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.5. First steps with TensorFlow"
      ],
      "metadata": {
        "id": "DpST4-9Kdj9o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Om een neuraal netwerk te trainen hebben we de volgende zaken nodig:\n",
        "\n",
        "- **Low-level** tensormanipulaties = **TensorFlow** API:\n",
        "\n",
        "  - tensors + variables\n",
        "  - tensoroperaties (bv. optelling, matrixvermenigvuldiging, activatiefuncties)\n",
        "  - backpropagation mbv `GradientTape` object\n",
        "\n",
        "- **High-level** deep learning concepten = **Keras** API\n",
        "  - modellen (bv. `Sequential`) die bestaan uit lagen (bv. `Dense`)\n",
        "  - lossfuncties (bv. RMSE)\n",
        "  - optimizers (bv. RMSprop)\n",
        "  - evaluatiemetrieken (bv. accuracy)\n",
        "  - training loop die mini-batch SGD uitvoert"
      ],
      "metadata": {
        "id": "5dp48Zrk9QOR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Constant tensors and variables"
      ],
      "metadata": {
        "id": "u9fg8w5X-oZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "tXwzdFg2-K1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensoren met enen en nullen:"
      ],
      "metadata": {
        "id": "-IUO4ql0_QIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.ones(shape=(2, 1))  # equivalent met np.ones(shape=(2, 1))\n",
        "print(x)"
      ],
      "metadata": {
        "id": "YzNfZ64_-wpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = tf.zeros(shape=(2, 1))  # equivalent met np.zeros(shape=(2, 1))\n",
        "print(y)"
      ],
      "metadata": {
        "id": "A2NQt9bG-0C2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random tensors:"
      ],
      "metadata": {
        "id": "9qbeGegt_TiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# standaardnormaal verdeelde random getallen\n",
        "x = tf.random.normal(shape=(3, 1), mean=0., stddev=1.)  # cfr np.random.normal(size=(3, 1), loc=0., scale=1.)\n",
        "print(x)"
      ],
      "metadata": {
        "id": "dREeI_nQ_BGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# uniform verdeelde random getallen tussen 0 en 1\n",
        "y = tf.random.uniform(shape=(3, 1), minval=0., maxval=1.)  # cfr np.random.uniform(size=(3, 1), low=0., high=1.)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "1QvuXDO6_bhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let op! TensorFlow tensoren zijn niet 'assignable':"
      ],
      "metadata": {
        "id": "XQ72JnsdAGCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    x[0, 0] = 0.\n",
        "except TypeError as err:  # geeft een TypeError\n",
        "    print(err)"
      ],
      "metadata": {
        "id": "e34Pyyea_jKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oplossing: TensorFlow variables!"
      ],
      "metadata": {
        "id": "gOqlEQFBAYAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v = tf.Variable(initial_value=tf.random.normal(shape=(3, 1)))\n",
        "print(v)"
      ],
      "metadata": {
        "id": "TfZ7f5NTATMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Toekenning gebeurt mbv methode `assign`:"
      ],
      "metadata": {
        "id": "xcUq2-gIAmt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v.assign(tf.ones((3, 1)))\n",
        "print(v)"
      ],
      "metadata": {
        "id": "bRX2Ld0kAidO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v[0, 0].assign(3.)\n",
        "print(v)"
      ],
      "metadata": {
        "id": "Wdaao3AJAs1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Methodes `assign_add` en `assign_sub` zijn equivalent met `+=` en `-=`:"
      ],
      "metadata": {
        "id": "7J3u25nKA1U5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v.assign_add(tf.ones((3, 1)))"
      ],
      "metadata": {
        "id": "XEIN84lEAyIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor operations: doing math in TensorFlow"
      ],
      "metadata": {
        "id": "cMbw8Q5BBCpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = 4 * tf.ones((2, 2))\n",
        "print(a)"
      ],
      "metadata": {
        "id": "lu_pqYIxA-pQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = tf.square(a)  # kwadraat, cfr np.square()\n",
        "print(b)"
      ],
      "metadata": {
        "id": "FxaWK7XkBZ8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = tf.sqrt(a)  # vierkantswortel, cfr np.sqrt()\n",
        "print(c)"
      ],
      "metadata": {
        "id": "jnWJoDoQBfP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = b + c  # optelling\n",
        "print(d)"
      ],
      "metadata": {
        "id": "OyxvvNuHBjHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "e = tf.matmul(a, b)  # matrixvermenigvuldiging, cfr np.dot()\n",
        "print(e)"
      ],
      "metadata": {
        "id": "oxhiDpb5BlfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "e *= d  # elementsgewijze vermenigvuldiging\n",
        "print(e)"
      ],
      "metadata": {
        "id": "UmEuZtCcBsIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alle bewerkingen worden 'on the fly' uitgevoerd = **eager execution**."
      ],
      "metadata": {
        "id": "rclCiKK0CAOE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A second look at the `GradientTape` API"
      ],
      "metadata": {
        "id": "2lXEuDxDCIE3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tot nu toe hebben we nog niks gedaan wat we niet in NumPy kunnen doen. Automatisch gradiënten berekenen van expressies die differentieerbaar zijn is echter iets wat we niet kunnen doen in NumPy maar wel in TensorFlow! We gebruiken hiervoor de `GradientTape`:"
      ],
      "metadata": {
        "id": "X0wjk3N4G_f8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_var = tf.Variable(initial_value=3.0)\n",
        "with tf.GradientTape() as tape:\n",
        "    result = tf.square(input_var)\n",
        "gradient = tape.gradient(result, input_var)  # afgeleide van x**2 voor x = 3\n",
        "print(gradient)  # moet 2 * x = 6 geven"
      ],
      "metadata": {
        "id": "mj-SBfAyBw0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`GradientTape` kan ook toegepast worden op een lijst van inputs en op meerdimensionale tensoren. Bij een neuraal netwerk zullen we de gradient van de loss berekenen tov de gewichten:\n",
        "\n",
        "> `gradients = tape.gradient(loss, weights)` zijn.\n",
        "\n",
        "In het voorbeeld hebben we een `Variable` gebruikt. Met een constante tensor lukt het ook, maar dan moeten we `tape.watch()` gebruiken om de tensoroperaties 'op te nemen':"
      ],
      "metadata": {
        "id": "4L7Yw79SH_Dx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_const = tf.constant(3.0)\n",
        "with tf.GradientTape() as tape:\n",
        "    tape.watch(input_const)  # watch constant\n",
        "    result = tf.square(input_const)\n",
        "gradient = tape.gradient(result, input_const)\n",
        "print(gradient)"
      ],
      "metadata": {
        "id": "onMiq7TcHqO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Waarom dat 'watchen'? Om resources te sparen! De gradiënt berekenen tov 'trainable variables' is zeer gebruikelijk in deep learning, maar tov constanten niet. Daarom moet je expliciet aangeven dat je de operaties wil 'tracken' waar die constante in betrokken is."
      ],
      "metadata": {
        "id": "ywj_rI5QJf0W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "De gradiënt is ook een functie en dus kunnen we de gradiënt van een gradiënt berekenen. Dat lukt ook in TensorFlow.\n",
        "\n",
        "Neem als voorbeeld de versnelling $a$ die de afgeleide is van de snelheid $v$ naar de tijd $t$, terwijl de snelheid $v$ de afgeleide is van de positie $x$ naar de tijd $t$:\n",
        "\n",
        "> $x = c t^2$\n",
        "\n",
        "> $v = \\frac{dx}{dt}$\n",
        "\n",
        "> $a = \\frac{dv}{dt} = \\frac{d^2x}{dt^2}$\n",
        "\n",
        "Stel dat $c$ een constante gelijk aan 4.9 is. Dan kunnen we de snelheid $v$ en versnelling $a$ eenvoudig als volgt berekenen:"
      ],
      "metadata": {
        "id": "fPJ5ILg6J-bu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = tf.Variable(10.0)  # pas op! 10.0 ipv 10 want moet float zijn!\n",
        "with tf.GradientTape() as outer_tape:\n",
        "    with tf.GradientTape() as inner_tape:\n",
        "        x = 4.9 * t**2\n",
        "    v = inner_tape.gradient(x, t)\n",
        "a = outer_tape.gradient(v, t)\n",
        "print(v)\n",
        "print(a)"
      ],
      "metadata": {
        "id": "53lg4yH9JQtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We nemen nu $x = c \\sqrt(t)$ en berekenen 100 punten mbv `tf.linspace` om daarna een plot te kunnen maken:"
      ],
      "metadata": {
        "id": "Gkw5hyZFN2N5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "\n",
        "t = tf.linspace(start=1.0, stop=100.0, num=100)  # cfr np.linspace(1, 100, 100)\n",
        "with tf.GradientTape() as outer_tape:\n",
        "    outer_tape.watch(t)  # t is een constante tensor!\n",
        "    with tf.GradientTape() as inner_tape:\n",
        "        inner_tape.watch(t)  # t is een constante tensor!\n",
        "        x = 4.9 * tf.sqrt(t)\n",
        "    v = inner_tape.gradient(x, t)\n",
        "a = outer_tape.gradient(v, t)\n",
        "\n",
        "plt.plot(t, x, 'k-', t, v, 'b-', t, a, 'r-');\n",
        "plt.xlabel('t');\n",
        "plt.legend(['x', 'v', 'a']);\n",
        "plt.grid();"
      ],
      "metadata": {
        "id": "YCkMcEANME1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`GradientTape` kan ook samengestelde functies differentiëren, bijv.:\n",
        "\n",
        "> $z = cos(x^2)$\n",
        "\n",
        "We weten dat de afgeleiden gelijk is aan:\n",
        "\n",
        "> $\\frac{dz}{dx}=-2x.sin(x^2)$"
      ],
      "metadata": {
        "id": "zUcmSgpga7jS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.linspace(start=-2*np.pi, stop=2*np.pi, num=1000)\n",
        "with tf.GradientTape() as tape:\n",
        "    tape.watch(x)  # t is een constante tensor!\n",
        "    z = tf.cos(tf.square(x))\n",
        "dzdx = tape.gradient(z, x)\n",
        "\n",
        "plt.plot(x, z, 'k-', # functie z\n",
        "         x, dzdx, 'r-',  # afgeleide van z berekend met GradientTape\n",
        "         x, -2*x*tf.sin(tf.square(x)), 'k:');  # analytisch berekende afgeleide van z\n",
        "plt.xlabel('$x$');\n",
        "plt.legend(['$z = cos(x^2)$', '$dz/dx$']);\n",
        "plt.grid();"
      ],
      "metadata": {
        "id": "yVg5VeJwbI6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Opdracht**\n",
        "\n",
        "Neem de volgende veeltermfunctie:\n",
        "\n",
        "> $y = \\frac{1}{16}(231x^6-315x^4+105x^2-5)$\n",
        "\n",
        "Maak een plot van deze functie over het interval $[-1, 1]$. Voeg onder deze plot een grafiek toe van de afgeleide $\\frac{dy}{dx}$ van deze functie. Bereken deze afgeleide met de TensorFlow `GradientTape`."
      ],
      "metadata": {
        "id": "3-EW4r2kLedq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2HIk8sp_MYMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### An end-to-end example: a linear classifier in pure TensorFlow"
      ],
      "metadata": {
        "id": "M9_wNqCPL9GW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lineaire classifiers hebben we uitvoerig in het vak Machine Learning besproken: **perceptron** en **logistic regression**. Daar hebben we ook SGD toegepast om deze modellen te trainen en we hebben het algoritme zelf geïmplementeerd in NumPy. Hier doen we het in TensorFlow."
      ],
      "metadata": {
        "id": "OsAKGr60Te_7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eerst creëren we een fictieve dataset voor binaire classificatie:"
      ],
      "metadata": {
        "id": "y5-zHDCyOj3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "num_samples_per_class = 1000\n",
        "negative_samples = np.random.multivariate_normal(\n",
        "    mean=[0, 3],\n",
        "    cov=[[1, 0.5],[0.5, 1]],\n",
        "    size=num_samples_per_class\n",
        ")\n",
        "positive_samples = np.random.multivariate_normal(\n",
        "    mean=[3, 0],\n",
        "    cov=[[1, 0.5],[0.5, 1]],\n",
        "    size=num_samples_per_class\n",
        ")\n",
        "\n",
        "inputs = np.vstack((negative_samples, positive_samples)).astype(np.float32)\n",
        "targets = np.vstack(\n",
        "    (np.zeros((num_samples_per_class, 1), dtype=\"float32\"),  # negatives = 0\n",
        "     np.ones((num_samples_per_class, 1), dtype=\"float32\"))   # positives = 1\n",
        ")\n",
        "\n",
        "plt.scatter(inputs[:, 0], inputs[:, 1], c=targets[:, 0]);\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "s1QWP0osLXeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We starten met het initialiseren van de gewichten en de bias:"
      ],
      "metadata": {
        "id": "zDz-UICnRVqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 2\n",
        "output_dim = 1\n",
        "W = tf.Variable(initial_value=tf.random.uniform(shape=(input_dim, output_dim)))  # random numbers\n",
        "b = tf.Variable(initial_value=tf.zeros(shape=(output_dim, )))  # nullen\n",
        "\n",
        "print(W.numpy())  # Variable omzetten naar numpy array\n",
        "print()\n",
        "print(b.numpy())"
      ],
      "metadata": {
        "id": "gB7Ql1SfRY-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "De forward pass wordt als volgt gecodeerd:"
      ],
      "metadata": {
        "id": "D4yd6nICPtil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model(inputs):\n",
        "    return tf.matmul(inputs, W) + b  # dot(inputs, W) + b"
      ],
      "metadata": {
        "id": "xNiqCV1nOwMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Als lossfunctie nemen we de MSE (= mean squared error):"
      ],
      "metadata": {
        "id": "o8dZsbokP5u8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def square_loss(targets, predictions):\n",
        "    per_sample_losses = tf.square(targets - predictions)  # squared losses\n",
        "    return tf.reduce_mean(per_sample_losses)  # gemiddelde"
      ],
      "metadata": {
        "id": "Nj-excOIPyzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "De functie voor één stap in de training loop zit er als volgt uit:"
      ],
      "metadata": {
        "id": "ZK-ZNVebQctA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.1\n",
        "\n",
        "def training_step(inputs, targets):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(inputs)\n",
        "        loss = square_loss(targets, predictions)\n",
        "    grad_loss_wrt_W, grad_loss_wrt_b = tape.gradient(loss, [W, b])\n",
        "    W.assign_sub(grad_loss_wrt_W * learning_rate)  # W -= grad(loss, W) * learning_rate\n",
        "    b.assign_sub(grad_loss_wrt_b * learning_rate)  # b -= grad(loss, b) * learning_rate\n",
        "    return loss"
      ],
      "metadata": {
        "id": "3-SxS-WIQGss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bij het trainen passen we full batch SGD toe. D.w.z. dat we de gewichten updaten obv de volledige dataset ipv obv mini-batches:"
      ],
      "metadata": {
        "id": "0-dDiGXQQ-Il"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for step in range(50):  # we nemen 50 epochs\n",
        "    loss = training_step(inputs, targets)\n",
        "    print(f\"Loss at step {step}: {loss:.4f}\")"
      ],
      "metadata": {
        "id": "3F0oXKNrQpqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We pltten het resultaat waarbij voorspellingen > 0.5 afgebeeld worden op 1 en de rest op 0. De classifier heeft dus de volgende vergelijking:\n",
        "\n",
        "> $W_0 x + W_1 y + b = 0.5$\n",
        "\n",
        "met $x$ en $y$ de 2 features. Hieruit kunnen we de vergelijking van de scheidende rechte afleiden:\n",
        "\n",
        "> $y = -\\frac{W_0}{W_1}x - \\frac{b-0.5}{W_1}$"
      ],
      "metadata": {
        "id": "R2olHMbvR4k0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.linspace(-1, 4, 100)\n",
        "y = - W[0] / W[1] * x + (0.5 - b) / W[1]  # scheidende rechte\n",
        "plt.plot(x, y, \"-r\");\n",
        "\n",
        "predictions = model(inputs)\n",
        "plt.scatter(inputs[:, 0], inputs[:, 1], c=predictions[:, 0] > 0.5);  # drempel = 0.5\n",
        "plt.grid();"
      ],
      "metadata": {
        "id": "o8MN12lDRLRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OPDRACHT**\n",
        "\n",
        "Implementeer Logistic Regression mbv TensorFlow. Gebruik dus de juiste TensorFlow functie als activatiefunctie. Voor de lossfunctie kan je ook gebruik maken van TensorFlow/Keras: https://www.tensorflow.org/api_docs/python/tf/keras/losses. Voorzie ook een methode om de nauwkeurigheid te berekenen: https://www.tensorflow.org/api_docs/python/tf/keras/metrics.\n",
        "\n",
        "Werk niet met losse stukjes code, maar structureer alles in een klasse. Test je code uit op de dataset die hierboven werd gecreëerd."
      ],
      "metadata": {
        "id": "78B8LhoK40QH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sQTT76FY73Zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OPDRACHT**\n",
        "\n",
        "Werkt je code ook voor de Halloween Candy dataset?\n",
        "\n",
        "Lees deze dataset in en test uit door te classificeren obv feature 'chocolate'.\n",
        "\n",
        "Vergelijk je resultaat met het Scikit-Learn algoritme."
      ],
      "metadata": {
        "id": "2NGWJWSwIVfr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l5drGrUjRp6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.6. Anatomy of a neural network: understanding core Keras APIs"
      ],
      "metadata": {
        "id": "yL78P8Q9TU3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deze code demonstreert hoe Keras modellen (= neurale netwerken) zijn opgebouwd adhv lagen. Een laag (Engels: layer) is de belangrijkste structuur in Keras, want alles is een `Layer` of interageert met layers. De \"traditionele\" laag is een `Dense` layer, een volledig geconnecteerde laag. Hieronder volgt een eenvoudige implementatie van deze klasse."
      ],
      "metadata": {
        "id": "UKtPWtoRY6do"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "class SimpleDense(keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, units, activation=None):\n",
        "        # units = aantal cellen = output size\n",
        "        # activation = tensorflow activatiefunctie\n",
        "        super().__init__()\n",
        "        self.units = units\n",
        "        self.activation = activation\n",
        "        self.built = False\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # initialiseert de parameters W en b\n",
        "        input_dim = input_shape[-1]\n",
        "        self.W = self.add_weight(shape=(input_dim, self.units), initializer=\"random_normal\")\n",
        "        self.b = self.add_weight(shape=(self.units,), initializer=\"zeros\")\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # forward loop: activation(dot(input, W) + b)\n",
        "        y = tf.matmul(inputs, self.W) + self.b\n",
        "        if self.activation is not None:\n",
        "              y = self.activation(y)\n",
        "        return y\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        # zorgt ervoor dat het object als functie kan aangeroepen worden\n",
        "        # zie Python documentatie: https://docs.python.org/3/reference/datamodel.html\n",
        "        if not self.built:\n",
        "            self.build(inputs.shape)\n",
        "            self.built = True\n",
        "        return self.call(inputs)"
      ],
      "metadata": {
        "id": "EMT_i1K8STaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_dense = SimpleDense(units=32, activation=tf.nn.relu)  # instantiatie\n",
        "input_tensor = tf.ones(shape=(2, 784))\n",
        "output_tensor = my_dense(input_tensor)  # dankzij __call__ kan object als functie aangeroepen worden\n",
        "print(output_tensor.shape)  # output_tensor.shape[1] = my_dense.units = 32"
      ],
      "metadata": {
        "id": "lKrugay_Fb6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "De eenvoudigste deep learning modellen bestaan uit een opeenvolging van lagen. In Keras gebruiken we hiervoor de `Sequantial` klasse, een subklasse van `Model`. Doordat methode `__call__()` de shape van de input automatisch in rekening brengt, hoeven we die niet mee te geven."
      ],
      "metadata": {
        "id": "LELisVBpZ_7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    SimpleDense(32, activation=tf.nn.relu),\n",
        "    SimpleDense(64, activation=tf.nn.relu),\n",
        "    SimpleDense(32, activation=tf.nn.relu),\n",
        "    SimpleDense(10, activation=tf.nn.softmax)\n",
        "])"
      ],
      "metadata": {
        "id": "UV6DjoeZFgp1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}