{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOsDtm+rrJTsyMBMOa3dPrk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alouwyck/vives-deep-learning/blob/main/topic9/Image_Segmentation_Challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p34cmLp6FrA6"
      },
      "source": [
        "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAALsAAABPCAYAAACzk7RlAAAT0ElEQVR4nO2df2wbZZrHv2nSi7jgSfcaTtHZ40onisCTtixlW09aEkRpHLckaRNPWk7i/khSwUnHae2s+Af24qBb0EkXu0f3VntXp9pdVrCxveLHtsSTtnAt1JPCsmohDhLs/UE81d4aUGon0PTSMPeHmcG//Y49Ths8H6mi2M+87zv1933neZ/3ed+pkSRJgo5OFbDuZjdAR2e10MWuUzXoYtepGnSx61QNuth1qgZd7DpVgy52naqh7mY3gITlyzP4Op7I+/26Rgrrt7VoUtf18+GC39duMqFuk1mTunRWl5q1sKj02d7ugiJct6ERf/Pn/ym7nuXLM/jzjgcL2mz4t3/B7U8+UXZdOqvPmhjZ69t2FxT711fjmtTzdbx4Oeu3bSEqy+v1AAA4joPJRJfVrluRm3F/P/vZfwAA7r77bjz00B7V168JsZNw/fwF1LftKq+Mcxc0as23YrBa2e+02Ffz/n796xchiiJ+8YtflnT9mpigkvjjX/7q5bLr+erF3xS1KbdD6ZRDTVlXr4mR/bbufVjXSBWcpH714m9gePKJkieqi8d+jhufzhVuR5dddbmJRBwnToyD50OgqEY4HA7YbJ1pNqIYxfj4OGZnIwAAjutHR4cNFEWllJPA+LgP09MCKKoRNpsNVqsVgUAAAOB0uhRbng8hGAwikYjDZKLhcHBgWTatrGAwAJ4PAQBstk44HFxafaltkutzODhN7i9XfSTtBsqbXq6JCSoAfOF4DNd+N1nQZv22Ftwx9RrWbWhUVfby5Rl81tFT1Pf/3vFjaPj7R4nKNJtNAACKopBIpHdSp9OliDMQ8GN42JV1PcMwmJgIKNcfOsQhEolk2cifzc2JAACXy4lgMJBVXmqdnZ0dmJ2dzVsfz4dw5MhQwTaR3h/PhzA87MqyMZlo+P1+xQXK1+7BwSGMjLgBAK2tVsWNKcVnh7RGWPzlS1L0LzYW/RPb2y2tzF8lLvf/Ln0o/Wnz94nKVlMuTRslmjZKNtteKRwOSzMzM9Lg4IBE00aJYe6RJEmSotE5iWHukWjaKDmdP5TC4bAUCk1KNtteiaaN0uDggCRJkuR0/lCiaaNksdwt+f0TUjgclny+40odNG2UJEmS/P4JxS4cDqd9RtNGaWZmRgqHwxJNGyWrdacUj8eleDyu1Of3T0jxeDytTdHonBQKTUoWy90STRsln+941v2FQpPSzMyM0k6aNiplF7q//n6HJEmSci/57k++F5bdKdG0UTp79gzx75DKmhG7JEnS/97fTiTKP23+vrR07p2i5S0c+7l05a//lqjM+LP/qqqt8g8VCk0qn8Xj8TThyT+o1boz7VpZkLJoZKH5/RNpdiMj/5wmdrkzuVxOSRAE5U9nZ4dE00bJ4xmTZmZmlGs8njEpGp1LK1PuHJltkjvKzMwM0f2lCjZXWbJdNDqniF/uSDJy55E7fbliXxM+u8yGsZ/gs709Re1ufDqHz/b2oG6TGbf/0+NYv3VLms9/7fU38NWLLxOHLNc1Urj9ycdLajNFNab8Pd0Hlx/tDMOkXZPqp0YiESwsLABAVtSDZVmcODGeUmbyfgIBPwIBf1ZbIpEInE4XBgYGceLEOLxeD7xeD0wmGkNDQxgYGIQoJt0hmjalXZvZxmL3J99jsbKiUVFxqSyW9Dpomk67r6qYoMrUt+3CbV32or67zI1P53B1+Omy66V+/JTqeYAavv0xk4hiVPl7qlAy7TL9bpmBgcGsSWJqWW73KFyuYfB8CIIgIBgMwO0egcFgUAQrdzAtyCwr1X+nKAoGgwELCwtZ9xfPWvcob3q5JkKPqXzP91Os36pNagAJf/nY4YqtmHZ02AAA09PTSmQEADyeZAzbYrHAZKIVu6NHvUpHiEQiGB/3pZXHsq0AgIsXp8EwDFiWBUVROHrUg6NHPYhGRQQCfhw6xGF01A2O64fH41Umk6IowmazKeXLT4dEIgG73Qaz2QSXy0l8fxzHZZUFAG73CADAaDSBYRilYx496lU6QiQSUSasHNdPXGch1tTIDiRTAzYGf4XYDx4sGIrUgvq2VvyV76cVK59hGDgcHILBAI4cGYLJRCORiCs/+NiYF0AyuiEIYUQiEbS2JhdxRDEKg8GQVt7g4BB4PoRIJILOThto2gRBEAAkOw7LshBFE9zuEQiC8E1YkVIiOiaTCSYTrbg5w8MunDgxrnxvMBjgcmVHjvKRWZbX6027P48neX9u96jS7pYWS1qUyWKxaCb2NTeyA0DdJjPuOP06as2VW7m7rcuOjYEXK1a+jDyyGo0miGIUiUQCHR02TE7yim/LMAz8/iCsViuApJvjcHCKWGQoioLfH4TDwSEevwpBEGAwGOB0uuD3BwHIIb8gOjpsiEQi39hQGBlxK6Jyu0cxMuKG0WhSROdwcOD5KdWrpW73KMbGPDnvT56bJMOdU0ocPxKJZLVbZuPGjarqT2XNxNlz8fXVOL7gHiuaqaiW2//xcWwY+4mmZVYCOUZvtVqzRKGTzZoc2WXWbWjEHadfB/XMU1jXSBW/oAi1Zhp3nH7tlhO62z0Cs9kEu92muADyKiiQHaXRyc2aHtlT+fpqHIvH/hOLx36u2pevNdOgfvwU8eroaiOKUdhsHVhYWABFUYpPm0gkYDAY4PcH84YGdb7lOyP2VK6fv4Brr72B5Q8+zOniyJs9buveh/q23Zpt/KgkcvQldUndarViZGRUFzoh30mx5+LGp3NY19hY0Xi5zq1N1YhdR2dNT1B1dNSgi12nalhzK6gkXL16VZX9hg0bKtSSm8v09DREMYpoNJr1HcMwynJ9pUkkEpidncXsbCRHvkuyLXJqRCVRLfZw+AIOHz5EbD8xEcjYbULO/v378OGHHxDZ9vQcwLFjyaX948f/C8eOvUB03UsvvYzdux/AjRs3sGULgy+//JLouscffwJPP/0MkW0mHs8Yjh71FjdEcnXx0qUPUFdX/KeSY++CIKTl2hQrn2Vb8+5EKhVRjCIQCGBqis/adFKoLfIuplI1UwjVbgzLtqK5uZnYnvQfPZNYLEYsdAA4eLC3pHpk6urq0NXVTWx/6tSpkutS829y4MDBokJPJBIYHXWjtdUKt3tEVfmJRAI8H4LL5URrK6tspC6VRCKB4WGXUhap0OVr5US1XDuzykW12GtqalQJ6+TJ36mtAgDwxhvkYmpqakJ7e3tJ9aTS29tHbCuKUXz88ceq6xDFKD766CPN2sTzIbS2WjE+7sva+lZK27xeD+x2W0lCk9uSK5deLYIgwG63ld35UilpgiqnbpIQi8Xy5l0Xgud5Ytvu7h7U1taqriOTnTt3qnpqTU2Rt1EmFCIfdc1mM+6777683w8Pu3DkyFDZIs8kEonAbrepEm0g4K9IW7xeT849uqVQktjvvHMzLBYLsb1aV2ZxcQHT0wKxvZoRuRA1NTXo63MQ25fioqm5plBbhoddmoyghSCtIxKJaCbIXAQCfk1G+JJDj2oEpnYEnJo6jZWVFSJbs9mMrVu3qiq/EI8++nfEtpcvX0YsFiO2n5+fx7vvvktsn0/sqyH01LqKddAf/ahyQpdR6//noiyx19SQ7QmMRCKqRKGmcxw+rG3yltlsxpYt5J1HzUh95sxpkC5Yb99+P8zm7ANUeT60akKXyXUURmp7tJ5I5uPZZ91lXV+y2JuamrB79wPE9qdOnSSyW15exptvniWyramp0TRcJtPbSz4BVzO3UGObqw3JqMsocRlakUgklK10mciHNJFgsVjgdLowMRHA8eM+ZdMKKYIgpO3PVUtZK6h9feSuDOkI+Pbb57G0tERku2PHDlUTSlJ6eg4QT3gvXHgHi4vFNycvLS3hrbfeJCqzrq4OPT0Hsj4fH/ep+rGNRhPGxjwIhwXMzYnKn8lJXvUgEQwGctZNGnxwODiEQlNwOl1gWRY2W+c32w2nlUOQSPD5fMWN8lCW2PfvfwT19fVEthcvXiQShRq3oLeXfDKphqamJrS1tRHZrqys4M03i4v43Ln/xvLyMlGZe/Y8nHUsBYCsDdaFkLfRcVx/1sokwzDweLyYnOSz9rEWQt4Ingpp5xsczD5hLPU7UsHLR+iVQllir6+vx759+4hsV1ZWMDU1VdBGkiTi0FxdXR26u8kXgdRy8KCap1Zx90SNC5NrHYPnQ8RhPavVCo/Hm7PDpCLvbSUVfCmhVpnGIjvJ5FMNijE9PV1yG8rOjentdeCVV14hsuX5UMEozvvv/x7z8/NEZXV02NDQ0EBkWwp2ux0NDQ1E6QOnT09heXkZ69evz/n9ysoKcSduaGhAR0dH1udqOkvmRuxCMAwDjutPO2wpH/Jqa64zaYoxOprceJ2vA5pMNCYmyP3/Uihb7Lt370ZTUxM+//zzorZvvfVWQVEUG/lTUTOJLIX6+np0dtrx298W38i8tLSEcDicdxX3vffeI3LhAKCnpydnegDpiGa1WlUnVNlsnURiB5I+eqrYrVYrUdvkqA3HcXlfYFCJfJhUyhZ7bW0tDhw4CJ/veFHbpaUlnD9/Dnv2PJzz+5MnySI2FEWVdoqrSvr6+ojEDiR/zHxiVzcPyf3kI/WNadqs+lF/5YpIbJsZZrTZOonrk9MR5CP3WJYFy7IlddBS0CTFt6+vj0jsQPJxnEvsn3zyMfEPSpIcpQW7dpE/taameDz33PM5vyN1QZqbm7Fjx86sz+WDjkjId86jVmQeUZc8VWxM9XF5yazIqNJWk4mGzWYDy7LKCWhao8nmDYZpwZ13biay5flQzoWVcidwlUBN+kAsFsOlS5eyPp+dnSXuxFqdfFVJRPFK2v9TFAW3u/zYf/KFBT4MDQ2ipcWC4WFXWTH1XGi2U8nhIBPF/Pw83n//91mfkz7qzWYztm/frqpt5aAmLSLXPahxYQ4dOkxse7PIJUCO68fYmHbZiXKqb2srq6noNRO7mvSBzFE8Fovh8uXLRNeqSdTSgnvuuUfFUyv76UQartu2bVvO9IC1Asf1Y2IioGpFlIRAwI/OztJSjjPRTOzNzc3KWYTFyNz4oFUmYKXo7ydzL/74x0/SRqFYLEb8I2mVuVlpComZZVkIwrRytqNW5HvNjlo0neX19vYRTaZEMYpPPvkYmzffBYDcX9++fftNGf0cDg7PP/8cURLXyZMn8cQT/wCAPB+otrZWs05ssViKLiaVV37xPasc1w+O61eOqp6eFkra05BKIpHAkSNDCIX4ku9PU7E/8kgXnnnmaVy/fr2oLc/z2Lz5LiwuLuDChXeIyr9Zo19TUxN27dqNd955u6gtz/OK2EmfWO3tDxb8AdVsipZzTm4FGIYBwyQnr4lEAoIQ/mZ/LK8q3CkjT2JLvT9Nj9JoaGjA3r3Zq3+5kH3Zs2fPEuWu50uOWi1IF7H+8If3MT8/j8XFBVy8eFGTsuW3U5CQ6ySBWwF5M7XbPQpBmEY4LGBszEPs+sqoybLMRPNzY0ijMpcuXUIsFiN2YR56aE9FH8/FsNv3ESW9SZIEng+B53miTtzQ0EC0/C6/VaMYU1O85lvjKoHJRIPj+uH3BxEOC8Q73+Qz3ktB85UZWZQkDTp16iTOnDlNVO7NnsA1NDTAbrfj1VdfLWrL8zzWryf7p923bz9RJ7LZbESRHfnlwKSP+iNHhojdLYPBgEgkuVlcFKNobSVb3h8YGCwYi5dfkNDSQib4SCRSUmpBRU4EI81zf+GFfyfKXTcYDMTZlZWENBPy7NkzOHfuHJEt6cRUzY/r9XqIVlEDAb+qSFjqE0jN8j5JzhNFURV/cldE7KSi+OKLL4jsurq6ymmOZrS1taGpqYnI9tq1a0VtmpubiUUsv96clOFhV94FGVGMYnTUrXqTdGZOOumyvihGi9YlnzdfSSoi9nvvvVfTEKGa3PJKUltbi+7u4u9hJeXgwV7ihTgAql7eBUBZhbTbbcrBQ3a7Da2trKqNIEAyuzEzKkSag57alsxXtsunmB06RN6RSz2yr2IHm2qV59Hc3IydO7OTo24WarYiFkPN+TtAcnQvJewmvyhMEISSF2Zy5chzXL+qxSNRjMLlcsJsNqGlxaL81+VyqtqYUqq7UzGxa5XncaslR23ZslWTpxbDMMRpCKk4nS5VZ/ZowdiYJ6+PrmajSCqluizl6KFiYm9ubsb99/+g7HJuxeQoLY7vKCdz0+8Pap6Dkg+HgysoMJZlMTAwuCptsVqtt6bYgfIf+Vu33prJUQ4Hp8rXzqSmpqasUCpFUQgEAhUf4XO9azUXbvdoRY40ScVoNMHnO1FWGRUVe1dXd1mbLLT0j7Wk3HnEAw+QR3XykfryXq0xGAwYG/OoclE8Hi/GxjyqTisgxWKxIBAIlB2arKjYKYrCww/n3oJXjNraWlVHSK825USItNo/S1EUfL5xHD/u08ytsVqtyhEcauG4fvD8lOoUgEIMDAzC7w9qsm2v4q+ZKfVsl/b29rJHv0rS3V3aU6u+vh779z+iaVtstk4ltbYU18ZgMMDh4DAxEShbWPITZ2IiAIeDK2mkl9sTDgtwu0c1W2xalbfllXICa3v7gwWPay4E6U55ALjrrrtUHeOXit8/gStXrhQ3TGHTpk0VT32Qj7wQRRGCkHwPbDQq4soVEUajCTSdfAqwbCssFktJR2OoQRAETE8L3ywcxZXXzgDfpiRTVCMYhoHVylbslAH91ZA6VYP+tjydqkEXu07VoItdp2rQxa5TNehi16kadLHrVA262HWqBl3sOlWDLnadqkEXu07VoItdp2rQxa5TNfw/229EA1oT9UMAAAAASUVORK5CYII=\" align=\"right\" /><br>\n",
        "\n",
        "\n",
        "**DEEP LEARNING**<br>\n",
        "Academiejaar 2022-2023<br>\n",
        "Andy Louwyck\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Segmentation Challenge"
      ],
      "metadata": {
        "id": "74qyJ9IcWepb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Opgave"
      ],
      "metadata": {
        "id": "zMzhvgHqFNgE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stel een neuraal netwerk op voor het segmenteren van de \"ellipses\" dataset. Deze dataset bestaat uit 128 x 128 RGB images met ellipsen en bijhorende masks die voor elke image de ellips aanduidt. De bedoeling is dat het model de ellips op elke image kan onderscheiden van de achtergrond. Er wordt geen rekening gehouden met de contour, d.w.z. dat er slechts 2 klassen moet worden onderscheiden: ellips en achtergrond. Probeer daarna een tweede model op te stellen dat geen neuraal netwerk is, maar toch ook in staat is om de ellipsen van hun achtergrond te onderscheiden. De beide modellen zullen geÃ«valueerd worden adhv een geheime testset. Wie de hoogste gemiddelde nauwkeurigheid haalt, wint de challenge!"
      ],
      "metadata": {
        "id": "WveXuOLNWuJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "cVh4HKrHFHk7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "De dataset zit in de zip-file `\"ellipses_train_val_only.zip\"`. Unzip de file en schrijf de dataset weg naar folder `\"ellipses\"`:"
      ],
      "metadata": {
        "id": "W0tb3xgdDCnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.unpack_archive(\"ellipses_train_val_only.zip\", \"ellipses\")"
      ],
      "metadata": {
        "id": "EEBsukYdDRP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dit is de folderstructuur van de dataset in Google Colab (met working directory 'content'):\n",
        "\n",
        "```\n",
        "content\n",
        "|_ ellipses\n",
        "   |_ train\n",
        "   |_ val\n",
        "   |_ (test)\n",
        "```\n",
        "(Subfolder 'test' ontbreekt bij jullie, maar zal wel aanwezig zijn bij de finale evaluatie na indienen!)"
      ],
      "metadata": {
        "id": "9wSsfFJpPbtm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "De dataset bestaat uit een training- en validatieset met respectievelijk 5000 en 500 images en bijhorende masks. De testset zit er niet bij en zal opnieuw gebruikt worden als finale evalutie na het indienen van je model. Gebruik onderstaande functie om de images en masks in te lezen en om te zetten naar NumPy arrays:"
      ],
      "metadata": {
        "id": "E6KgdJqrCwDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import load_img, img_to_array, array_to_img\n",
        "\n",
        "def images_from_dir_to_array(nsamples, subset=\"test\", folder=\"./ellipses\"):\n",
        "    # nsamples is het aantal images in de dataset\n",
        "    # folder is de hoofddirectory van de dataset\n",
        "    # subset is de subdirectory van de subdataset\n",
        "    # retourneert array X met de omgezette images en array y met de omgezette masks\n",
        "\n",
        "    X, y = [], []\n",
        "\n",
        "    for id in range(1, nsamples + 1):\n",
        "\n",
        "        image_file = os.path.join(folder, subset, 'image_' + str(id) + \".jpg\")\n",
        "        mask_file = os.path.join(folder, subset, 'mask_' + str(id) +\".png\")\n",
        "\n",
        "        im = img_to_array(load_img(image_file))\n",
        "        mask = img_to_array(load_img(mask_file, color_mode=\"grayscale\"))\n",
        "\n",
        "        X.append(im)\n",
        "        y.append(mask)\n",
        "\n",
        "    return np.array(X, dtype=\"float32\"), np.array(y, dtype=\"bool\")"
      ],
      "metadata": {
        "id": "UhIYosCeClkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X, train_y = images_from_dir_to_array(nsamples=5000, subset=\"train\")\n",
        "val_X, val_y = images_from_dir_to_array(nsamples=500, subset=\"val\")\n",
        "\n",
        "print(train_X.shape)\n",
        "print(train_y.shape)\n",
        "print(val_X.shape)\n",
        "print(val_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-ZCuvZSDZG_",
        "outputId": "adfc7f54-648e-4dcc-9423-43d1118b2f43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5000, 128, 128, 3)\n",
            "(5000, 128, 128, 1)\n",
            "(500, 128, 128, 3)\n",
            "(500, 128, 128, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Je ziet dus dat array `X` de originele RGB images bevat van 128 x 128 en array `y` de bijhorende masks die uiteraard ook size 128 x 128 hebben maar slechts 1 kanaal hebben omdat de waarden 0 of 1 zijn."
      ],
      "metadata": {
        "id": "Ie_hJJ-7D6ZG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vul hier gerust code aan om de dataset te verkennen!"
      ],
      "metadata": {
        "id": "rP83fleANz3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DwD2LiaTN2pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ConvNet"
      ],
      "metadata": {
        "id": "B8rgxCT0FiY2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Als voorbeeld trainen we hier een slecht presterend neuraal netwerk. Het is natuurlijk de bedoeling dat je dit model verbetert!"
      ],
      "metadata": {
        "id": "elZI2cbNE2Ss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "\n",
        "size = 128\n",
        "\n",
        "inputs = keras.Input(shape=(size, size, 3))\n",
        "x = layers.Rescaling(1./255)(inputs)\n",
        "x = layers.Conv2D(1, 3, strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "x = layers.Conv2D(1, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(1, 3, activation=\"relu\", padding=\"same\")(x)\n",
        "x = layers.Conv2DTranspose(1, 3, activation=\"relu\", padding=\"same\", strides=2)(x)\n",
        "outputs = layers.Conv2D(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
        "\n",
        "cnn = keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "M7_nCUoVFhoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We compileren het model:"
      ],
      "metadata": {
        "id": "n30l3fG1LCnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\")"
      ],
      "metadata": {
        "id": "pzT9lDr7FoES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We trainen het model en slaan de beste versie op in `\"ellips_segmentation.h5\"`."
      ],
      "metadata": {
        "id": "l-8k4zeVLESJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"ellips_segmentation.h5\"\n",
        "\n",
        "history = cnn.fit(train_X, train_y,\n",
        "                  epochs=2,\n",
        "                  batch_size=64,\n",
        "                  callbacks=[keras.callbacks.ModelCheckpoint(filename, save_best_only=True)],\n",
        "                  validation_data=(val_X, val_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iflr1h_XGpJz",
        "outputId": "8bd42174-223c-4679-a2ed-8cf7fc27c78f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "79/79 [==============================] - 39s 484ms/step - loss: 0.6755 - val_loss: 0.6607\n",
            "Epoch 2/2\n",
            "79/79 [==============================] - 43s 541ms/step - loss: 0.6469 - val_loss: 0.6334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We moeten nu nog een classifier schrijven die de voorspelde kans van elke pixel omzet naar 0 of 1. We gebruiken hier eenvoudigweg de `round` functie voor:"
      ],
      "metadata": {
        "id": "oTXoeHN4I8yg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cnn_classifier(X):\n",
        "    # X is de array met images\n",
        "    # laadt model \"ellips_segmentation.keras\" in\n",
        "    # retourneert de voorspelde masks y_pred\n",
        "    cnn = keras.models.load_model(filename)  # PAS OP! filename is globale variabele!\n",
        "    return cnn.predict(X).round()"
      ],
      "metadata": {
        "id": "UIkx4sSAJK1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ook deze functie kan je verbeteren, door bijvoorbeeld een andere threshold te gebruiken (want de `round` functie gebruikt natuurlijk 0.5 als drempel)."
      ],
      "metadata": {
        "id": "Fve6F9DNJhyM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Laten we de functie eens testen:"
      ],
      "metadata": {
        "id": "tXHLNc_iMSqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = cnn_classifier(train_X)\n",
        "print(y_pred.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-u4T_Av0Jt5Z",
        "outputId": "b34235d0-8383-4888-c1b7-928bb8a14e39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 17s 109ms/step\n",
            "(5000, 128, 128, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Out-of-the-box Model"
      ],
      "metadata": {
        "id": "7PyiDumhHNmc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Denk nu ook eens 'out-of-the-box' en probeer zelf een model te ontwerpen dat geen gebruik maakt van deep learning om tot hetzelfde of misschien zelfs een beter resultaat te komen!"
      ],
      "metadata": {
        "id": "N6KpB3BxhScs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Je out-of-the-box model implementeer je als functie met de volgende signatuur:\n",
        "\n",
        "```python\n",
        "def out_of_the_box_model(X):\n",
        "    # input zijn de images X\n",
        "    ...  # hier komt de code\n",
        "    return y_pred  # de functie retourneert de voorspellingen\n",
        "```"
      ],
      "metadata": {
        "id": "yAD1F04m76AS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Als voorbeeld implementeren we een \"naÃ¯eve\" classifier die alles als achtergrond voorspeld. Het resultaat van deze classifier is een baseline en onze modellen moeten dus sowieso beter doen!"
      ],
      "metadata": {
        "id": "pvrUthmXH0KS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def out_of_the_box_model(X):\n",
        "    # X is de array met images\n",
        "    # retourneert array y_pred met voorspelde masks\n",
        "    return np.zeros(X.shape[:-1], dtype=\"bool\")  # alles achtergrond (= False)"
      ],
      "metadata": {
        "id": "1DPuV4n5ICuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uiteraard is het de bedoeling dat je hier een beter model uitwerkt!"
      ],
      "metadata": {
        "id": "3qN3Gp_EIURW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluatie"
      ],
      "metadata": {
        "id": "PT0zuF31IeSu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Je deep learning model en je out-of-the-box model zullen geÃ«valueerd worden adhv de testset die uit 1000 images en bijhorende masks bestaat. De nauwkeurigheid zal berekend voor elke pixel in de dataset. Dat betekent dat het aantal correct geclassificeerde pixels zal gedeeld worden door het totaal aantal pixels, i.e. 128 x 128 x 1000. Dit is functie:"
      ],
      "metadata": {
        "id": "gRwyGObfX471"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(classifier, X, y):\n",
        "    # classifier is een functie met X als input die de voorspelde masks y_pred retourneert\n",
        "    # X zijn de images\n",
        "    # y zijn de masks\n",
        "    # retourneert de nauwkeurigheid van alle pixels\n",
        "    y_pred = classifier(X)\n",
        "    return (y.squeeze() == y_pred.squeeze()).sum() / y.size"
      ],
      "metadata": {
        "id": "awi5lWxbIpFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Laten we eens de nauwkeurigheid van onze convnet en naÃ¯eve classifier berekenen voor de trainingset:"
      ],
      "metadata": {
        "id": "Agbkw_FeIycS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_accuracy(cnn_classifier, train_X, train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZJSp2BEI4D_",
        "outputId": "f9843763-f6bd-48b8-e10e-8a1c53ade61c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 17s 106ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.883523486328125"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_accuracy(out_of_the_box_model, train_X, train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3agXrlqLYFz",
        "outputId": "c07d8fc0-ff81-41f8-93e5-3090f8bb3067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.883523486328125"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ze scoren even goed omdat ze alle twee enkel achtergrond voorspellen, en blijkbaar is 88.35% van de pixels effectief ook achtergrond. Dit toont nogmaals het belang aan van een baseline model!"
      ],
      "metadata": {
        "id": "Y-VEtd-0LimC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "De nauwkeurigheid voor de validatieset is uiteraard ook twee maal hetzelfde en ligt eveneens rond de 88%:"
      ],
      "metadata": {
        "id": "Zds8lDyrLu6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_accuracy(cnn_classifier, val_X, val_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEnzrEuNLufE",
        "outputId": "02881322-22d2-4012-ce7d-0ff137930dd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 2s 107ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8801942138671875"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_accuracy(out_of_the_box_model, val_X, val_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFLhLM27L1_m",
        "outputId": "00770f69-ca69-4a12-bed9-4e37678a3019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8801942138671875"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Indienen"
      ],
      "metadata": {
        "id": "xg_uqtZVMH_c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Klaar? Dien je notebook in op Toledo samen met je opgeslagen neuraal netwerk (als HDF5-file).\n",
        "\n",
        "Wie de hoogste gemiddelde nauwkeurigheid haalt op beide modellen voor de geheime testset wint de challenge!\n"
      ],
      "metadata": {
        "id": "ELpZ65wKHX2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hieronder zie je de code die zal uitgevoerd worden in Google Colab (met het resultaat voor onze twee slechte modellen!):"
      ],
      "metadata": {
        "id": "_BoWZZabMwk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_X, test_y = images_from_dir_to_array(nsamples=1000, subset=\"test\")\n",
        "acc_cnn = get_accuracy(cnn_classifier, test_X, test_y)\n",
        "acc_obm = get_accuracy(out_of_the_box_model, test_X, test_y)\n",
        "print(\"ConvNet acc:\", acc_cnn)\n",
        "print(\"Out-of-the-box acc:\", acc_obm)\n",
        "print(\"Gemiddelde:\", (acc_cnn + acc_obm) / 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZXipD6dM2Bj",
        "outputId": "2d8e9e89-e3b0-479e-bc30-4903c2ff045e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 4s 117ms/step\n",
            "ConvNet acc: 0.8779314575195313\n",
            "Out-of-the-box acc: 0.8779314575195313\n",
            "Gemiddelde: 0.8779314575195313\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Wie dus de hoogste gemiddelde nauwkeurigheid haalt op de twee modellen, wint de challenge!**"
      ],
      "metadata": {
        "id": "QUf7N6nV-I_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veel succes!!"
      ],
      "metadata": {
        "id": "hISoHKpfPDpb"
      }
    }
  ]
}