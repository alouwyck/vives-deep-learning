{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO1I4EDwpxcIlJh9p3ev7yn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "65130c6b994d480580c30012c245f0e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c988ea5849ff4217a3537b3fec3b3809",
              "IPY_MODEL_f6e623a69ea74664b096423ecc4bfd57",
              "IPY_MODEL_057590d7e3814bb49f0269183c3dc8a7"
            ],
            "layout": "IPY_MODEL_4012317929c649b993daffcd847c19b2"
          }
        },
        "c988ea5849ff4217a3537b3fec3b3809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_753f343761f8416a8ea41a31bd3342d3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_07860f75495842379c9a4e62adf05dc4",
            "value": "Loading pipeline components...: 100%"
          }
        },
        "f6e623a69ea74664b096423ecc4bfd57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7d05282c9d3438fb13278e7863db661",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2858218f18aa4d82a5990de9f9a51e02",
            "value": 7
          }
        },
        "057590d7e3814bb49f0269183c3dc8a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e9e5124ebd74ebe8c213e1c02338f79",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7b8465fb28304d18b403c13e70aed297",
            "value": " 7/7 [00:01&lt;00:00,  3.84it/s]"
          }
        },
        "4012317929c649b993daffcd847c19b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "753f343761f8416a8ea41a31bd3342d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07860f75495842379c9a4e62adf05dc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7d05282c9d3438fb13278e7863db661": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2858218f18aa4d82a5990de9f9a51e02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e9e5124ebd74ebe8c213e1c02338f79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b8465fb28304d18b403c13e70aed297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alouwyck/vives-deep-learning/blob/main/topic17/2_GenAI_Hugging_Face.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p34cmLp6FrA6"
      },
      "source": [
        "<img src=\"data:image/png;base64,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\" align=\"right\" /><br>\n",
        "\n",
        "\n",
        "**DEEP LEARNING**<br>\n",
        "Academiejaar 2023-2024<br>\n",
        "Andy Louwyck\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GENERATIVE AI WITH HUGGING FACE**"
      ],
      "metadata": {
        "id": "EX4Y9JjVwZ0E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Generative AI Applications with Gradio"
      ],
      "metadata": {
        "id": "Q9O5nnnS7GYI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To become familiar with the possibilities of generative AI, let's go through the examples of the following online course:\n",
        "\n",
        "https://learn.deeplearning.ai/huggingface-gradio/"
      ],
      "metadata": {
        "id": "CV-asusf7DGE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The examples in the course make use of an API. Here it is shown how to run the examples 'locally' in Google Colab. The code looks very similar. For more information, check the [Pipelines](https://huggingface.co/docs/transformers/main_classes/pipelines) documentation page on Hugging Face."
      ],
      "metadata": {
        "id": "gcHpSUUIyblo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Google Colab you first need to install\n",
        "- the [Hugging Face](https://huggingface.co/) `transformers` library\n",
        "- and the [gradio](https://www.gradio.app/) library."
      ],
      "metadata": {
        "id": "vQ6I-W9wwIoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets"
      ],
      "metadata": {
        "id": "IFDZK7Wss3d1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "yKC9yV2pu8t_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we import `pipeline` from the `transformers` library and `gradio`. For the latter, it is common to use alias `gr`:"
      ],
      "metadata": {
        "id": "QUw6lYCnwHJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "sEHl1zD1xrm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're ready now to go through the course!"
      ],
      "metadata": {
        "id": "Ax_ALF-dweqC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### L1: NLP tasks with a simple interface"
      ],
      "metadata": {
        "id": "doe6tmVNwAS6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Building a text summarization app"
      ],
      "metadata": {
        "id": "R7rdrqxfyBXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_completion = pipeline(\"summarization\",\n",
        "                          model=\"sshleifer/distilbart-cnn-12-6\")  # sshleifer with double s! (typo in example notebook on deeplearning.ai)\n",
        "\n",
        "def summarize(input):\n",
        "    output = get_completion(input)\n",
        "    return output[0]['summary_text']"
      ],
      "metadata": {
        "id": "XejOH18ssxJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = ('''The tower is 324 metres (1,063 ft) tall, about the same height\n",
        "        as an 81-storey building, and the tallest structure in Paris.\n",
        "        Its base is square, measuring 125 metres (410 ft) on each side.\n",
        "        During its construction, the Eiffel Tower surpassed the Washington\n",
        "        Monument to become the tallest man-made structure in the world,\n",
        "        a title it held for 41 years until the Chrysler Building\n",
        "        in New York City was finished in 1930. It was the first structure\n",
        "        to reach a height of 300 metres. Due to the addition of a broadcasting\n",
        "        aerial at the top of the tower in 1957, it is now taller than the\n",
        "        Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the\n",
        "        Eiffel Tower is the second tallest free-standing structure in France\n",
        "        after the Millau Viaduct.''')\n",
        "\n",
        "get_completion(text)"
      ],
      "metadata": {
        "id": "ksMbHcEvuURd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or using function `summarize`:"
      ],
      "metadata": {
        "id": "1r8KW08oyub_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summarize(text)"
      ],
      "metadata": {
        "id": "qunjzXOiugh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Trying out the Hugging Face Inference API"
      ],
      "metadata": {
        "id": "Hn3K4X1w2XGh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First get a Hugging Face Inference API key: https://youtu.be/jo_fTD2H4xA?si=GNrDbhkPNOqu9HGa\n",
        "\n",
        "Copy the key from the Hugging Face website.\n",
        "\n",
        "It's safer to save your key in an .env-file, which can be created easily using the Linux `echo` command:"
      ],
      "metadata": {
        "id": "nS3vROwj2h_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"HF_API_KEY=your_key\" > .env"
      ],
      "metadata": {
        "id": "SDT4f6wx5-V3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Of course you need to replace `your_key` by the actual key you copy-pasted from the Hugging Face website.\n",
        "\n",
        "Check if the .env-file indeed contains your key:"
      ],
      "metadata": {
        "id": "t-EgdPuv5clz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat .env"
      ],
      "metadata": {
        "id": "SmQ6-R1L5BoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To be able to run the code from the course we have to install the `dotenv` library:"
      ],
      "metadata": {
        "id": "xM8yxZx76J9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "id": "4SXuW6gBpqgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the code snippet from the course to read the .env-file and assign your key to variable `hf_api_key`:"
      ],
      "metadata": {
        "id": "c6RbbKtw6TE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import io\n",
        "from IPython.display import Image, display, HTML\n",
        "from PIL import Image\n",
        "import base64\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "hf_api_key = os.environ['HF_API_KEY']\n",
        "hf_api_key"
      ],
      "metadata": {
        "id": "oXBe9AgKn_Qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Of course it is safer to delete commands and output that display your key!"
      ],
      "metadata": {
        "id": "yOtWzoAp61fu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now go to the Hugging Face page for `distilbart-cnn-12-6`: https://huggingface.co/sshleifer/distilbart-cnn-12-6\n",
        "\n",
        "On the right, you see a \"Deploy\" button. Click on it and then on \"Inference API\" to get the `API_URL`. You may also copy-paste the following code:"
      ],
      "metadata": {
        "id": "wG0zKwX37Ddg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "API_URL = \"https://api-inference.huggingface.co/models/sshleifer/distilbart-cnn-12-6\"\n",
        "headers = {\"Authorization\": f\"Bearer {hf_api_key}\"}\n",
        "\n",
        "def query(payload):\n",
        "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
        "\treturn response.json()\n",
        "\n",
        "output = query(dict(inputs=text))\n",
        "output"
      ],
      "metadata": {
        "id": "Vs1Pdb7jsh5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's easy now to redefine the `summarize` function so it calls the API instead of using the pipeline:\n",
        "\n"
      ],
      "metadata": {
        "id": "MPQi254d9Emf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(input):\n",
        "    output = query(dict(inputs=text))\n",
        "    return output[0]['summary_text']"
      ],
      "metadata": {
        "id": "sasBNS5j9H0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarize(text)"
      ],
      "metadata": {
        "id": "IhIL49yX9c1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Getting started with Gradio `gr.Interface`"
      ],
      "metadata": {
        "id": "TP_bwRCTyahc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gr.close_all()\n",
        "demo = gr.Interface(fn=summarize,  # function summarize\n",
        "                    inputs=\"text\", outputs=\"text\")\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "q-IIov6Zu4Y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can add `demo.launch(share=True)` to create a public link to share with your team or friends:"
      ],
      "metadata": {
        "id": "70SVN0dyypB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "demo.launch(share=True)"
      ],
      "metadata": {
        "id": "lYtcCXcrvEWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Building a Named Entity Recognition app"
      ],
      "metadata": {
        "id": "5aueMZO3yr_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_completion = pipeline(\"ner\", model=\"dslim/bert-base-NER\")\n",
        "\n",
        "def ner(input):\n",
        "    output = get_completion(input)\n",
        "    return {\"text\": input, \"entities\": output}"
      ],
      "metadata": {
        "id": "lpPt8bwFy0Wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.close_all()\n",
        "demo = gr.Interface(fn=ner,  # function ner\n",
        "                    inputs=[gr.Textbox(label=\"Text to find entities\", lines=2)],\n",
        "                    outputs=[gr.HighlightedText(label=\"Text with entities\")],\n",
        "                    title=\"NER with dslim/bert-base-NER\",\n",
        "                    description=\"Find entities using the `dslim/bert-base-NER` model under the hood!\",\n",
        "                    allow_flagging=\"never\",\n",
        "                    #Here we introduce a new tag, examples, easy to use examples for your application\n",
        "                    examples=[\"My name is Andrew and I live in California\",\n",
        "                              \"My name is Poli and work at HuggingFace\"])\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "gpNBCIykzJRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### L2: Image captioning app"
      ],
      "metadata": {
        "id": "B7usBBkdL5mA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import IPython.display\n",
        "from PIL import Image\n",
        "import base64"
      ],
      "metadata": {
        "id": "JEt2pfU1M-Fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Building an image captioning app"
      ],
      "metadata": {
        "id": "mA03mN2NMI3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_completion = pipeline(\"image-to-text\", model=\"Salesforce/blip-image-captioning-base\")\n",
        "\n",
        "def summarize(input):\n",
        "    output = get_completion(input)\n",
        "    return output[0]['generated_text']"
      ],
      "metadata": {
        "id": "xE4hcrzuMJT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The free images are available on: https://free-images.com/"
      ],
      "metadata": {
        "id": "AqyMJXA9M0Ir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_url = \"https://free-images.com/sm/9596/dog_animal_greyhound_983023.jpg\"\n",
        "display(IPython.display.Image(url=image_url))\n",
        "get_completion(image_url)"
      ],
      "metadata": {
        "id": "vGFoOOMOM4HG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or using function `summarize`:"
      ],
      "metadata": {
        "id": "Vg65nkT5y9d8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summarize(image_url)"
      ],
      "metadata": {
        "id": "jGmAehAnNM3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Captioning with `gr.Interface()`"
      ],
      "metadata": {
        "id": "-bAqZk7bNe7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def image_to_base64_str(pil_image):\n",
        "    byte_arr = io.BytesIO()\n",
        "    pil_image.save(byte_arr, format='PNG')\n",
        "    byte_arr = byte_arr.getvalue()\n",
        "    return str(base64.b64encode(byte_arr).decode('utf-8'))\n",
        "\n",
        "def captioner(image):\n",
        "    base64_image = image_to_base64_str(image)\n",
        "    result = get_completion(base64_image)\n",
        "    return result[0]['generated_text']"
      ],
      "metadata": {
        "id": "pgXjWHGUNnsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.close_all()\n",
        "demo = gr.Interface(fn=captioner,\n",
        "                    inputs=[gr.Image(label=\"Upload image\", type=\"pil\")],\n",
        "                    outputs=[gr.Textbox(label=\"Caption\")],\n",
        "                    title=\"Image Captioning with BLIP\",\n",
        "                    description=\"Caption any image using the BLIP model\",\n",
        "                    allow_flagging=\"never\",\n",
        "                    # you need to upload these example images\n",
        "                    # in colab: left pane > Files > Upload to storage session\n",
        "                    examples=[\"christmas_dog.jpg\", \"bird_flight.jpg\", \"cow.jpg\"])\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "8GjJ6vWVNqSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### L3: Image generation app"
      ],
      "metadata": {
        "id": "9FaeyWEKRlWN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this lesson [stable diffusion](https://stability.ai/) is applied, which requires the use of GPU.\n",
        "\n",
        "Switching to GPU in Google Colab is done as follows:\n",
        "- click on menu item \"Runtime\"\n",
        "- select \"Change runtime type\"\n",
        "- set \"Hardware accelerator\" to \"T4 GPU\""
      ],
      "metadata": {
        "id": "fHEWl127woNw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next the `diffusers` library (see https://huggingface.co/docs/diffusers/quicktour) needs te be installed:"
      ],
      "metadata": {
        "id": "ZmNEMxyzSlvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade diffusers accelerate transformers"
      ],
      "metadata": {
        "id": "SKHyn1uSSiC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the runtime type has been changed, we also need to re-install gradio:"
      ],
      "metadata": {
        "id": "rMNc2IR-VaHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "PziOSO_eU7Vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Of course we also need to re-import the required packages and libraries:"
      ],
      "metadata": {
        "id": "QzbvkXslUJG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from diffusers import DiffusionPipeline\n",
        "import gradio as gr\n",
        "import io\n",
        "import IPython.display\n",
        "from PIL import Image\n",
        "import base64"
      ],
      "metadata": {
        "id": "8AV5EvPdS1ZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Building an image generation app"
      ],
      "metadata": {
        "id": "4oHeyb30S6oE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = DiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\n",
        "pipeline.to(\"cuda\")  # we want to use GPU!!!\n",
        "\n",
        "def get_completion(prompt):\n",
        "    return pipeline(prompt).images[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "65130c6b994d480580c30012c245f0e9",
            "c988ea5849ff4217a3537b3fec3b3809",
            "f6e623a69ea74664b096423ecc4bfd57",
            "057590d7e3814bb49f0269183c3dc8a7",
            "4012317929c649b993daffcd847c19b2",
            "753f343761f8416a8ea41a31bd3342d3",
            "07860f75495842379c9a4e62adf05dc4",
            "a7d05282c9d3438fb13278e7863db661",
            "2858218f18aa4d82a5990de9f9a51e02",
            "6e9e5124ebd74ebe8c213e1c02338f79",
            "7b8465fb28304d18b403c13e70aed297"
          ]
        },
        "id": "QxhBDEhqSF6H",
        "outputId": "8ed8f794-0d1c-401a-d5e4-e79406004159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "65130c6b994d480580c30012c245f0e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
            "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"a dog in a park\"\n",
        "result = get_completion(prompt)\n",
        "result"
      ],
      "metadata": {
        "id": "4xWzCcPUTCpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generating with `gr.Interface()`"
      ],
      "metadata": {
        "id": "mvT0dfpATKpR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we don't need the helper functions from the notebook shown in the course."
      ],
      "metadata": {
        "id": "hNtNg_aExpwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gr.close_all()\n",
        "demo = gr.Interface(fn=get_completion,  # we may pass function 'get_completion' as it retunrs an image\n",
        "                    inputs=[gr.Textbox(label=\"Your prompt\")],\n",
        "                    outputs=[gr.Image(label=\"Result\")],\n",
        "                    title=\"Image Generation with Stable Diffusion\",\n",
        "                    description=\"Generate any image with Stable Diffusion\",\n",
        "                    allow_flagging=\"never\",\n",
        "                    examples=[\"the spirit of a tamagotchi wandering in the city of Vienna\",\n",
        "                              \"a mecha robot in a favela\"])\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "eWhTGwAqWByJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Building a more advanced interface"
      ],
      "metadata": {
        "id": "XHcHhan2eK2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(prompt, params):  # we need 'params' as additional input\n",
        "    return pipeline(prompt, **params).images[0]\n",
        "\n",
        "def generate(prompt, negative_prompt, steps, guidance, width, height):\n",
        "    params = {\n",
        "        \"negative_prompt\": negative_prompt,\n",
        "        \"num_inference_steps\": steps,\n",
        "        \"guidance_scale\": guidance,\n",
        "        \"width\": width,\n",
        "        \"height\": height\n",
        "    }\n",
        "\n",
        "    return get_completion(prompt, params)"
      ],
      "metadata": {
        "id": "memqSQs4eYQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate(prompt=\"dog in a park\",\n",
        "         negative_prompt=\"low quality\",  # negative prompt is what we don't want\n",
        "         steps=25,\n",
        "         guidance=7,\n",
        "         # width and height must be divisible by 8\n",
        "         width=8*40,\n",
        "         height=8*40)"
      ],
      "metadata": {
        "id": "lJw256JQiTaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.close_all()\n",
        "demo = gr.Interface(fn=generate,\n",
        "                    inputs=[\n",
        "                        gr.Textbox(label=\"Your prompt\"),\n",
        "                        gr.Textbox(label=\"Negative prompt\"),\n",
        "                        gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n",
        "                                 info=\"In how many steps will the denoiser denoise the image?\"),\n",
        "                        gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n",
        "                                  info=\"Controls how much the text prompt influences the result\"),\n",
        "                        gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512),\n",
        "                        gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512),\n",
        "                    ],\n",
        "                    outputs=[gr.Image(label=\"Result\")],\n",
        "                    title=\"Image Generation with Stable Diffusion\",\n",
        "                    description=\"Generate any image with Stable Diffusion\",\n",
        "                    allow_flagging=\"never\"\n",
        "                    )\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "UKn0ZYSGeVgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `gr.Blocks()` to the rescue!"
      ],
      "metadata": {
        "id": "hPZtyxqxe1Cb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Image Generation with Stable Diffusion\")\n",
        "    prompt = gr.Textbox(label=\"Your prompt\")\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            negative_prompt = gr.Textbox(label=\"Negative prompt\")\n",
        "            steps = gr.Slider(label=\"Inference Steps\", minimum=1, maximum=100, value=25,\n",
        "                      info=\"In many steps will the denoiser denoise the image?\")\n",
        "            guidance = gr.Slider(label=\"Guidance Scale\", minimum=1, maximum=20, value=7,\n",
        "                      info=\"Controls how much the text prompt influences the result\")\n",
        "            width = gr.Slider(label=\"Width\", minimum=64, maximum=512, step=64, value=512)\n",
        "            height = gr.Slider(label=\"Height\", minimum=64, maximum=512, step=64, value=512)\n",
        "            btn = gr.Button(\"Submit\")\n",
        "        with gr.Column():\n",
        "            output = gr.Image(label=\"Result\")\n",
        "\n",
        "    btn.click(fn=generate, inputs=[prompt,negative_prompt,steps,guidance,width,height], outputs=[output])\n",
        "gr.close_all()\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "2ExeYHGRe69j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now try to hide the \"advanced options\" using Gradio's `Accordion` widget!"
      ],
      "metadata": {
        "id": "wMmViKbZnZYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your code here!"
      ],
      "metadata": {
        "id": "8TtSKg0qzeMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### L4: Describe-and-Generate game"
      ],
      "metadata": {
        "id": "3ut6osKyoJZZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bringing together the functions from previous lessons!"
      ],
      "metadata": {
        "id": "JWFfyJ_gyJN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "def image_to_base64_str(pil_image):\n",
        "    byte_arr = io.BytesIO()\n",
        "    pil_image.save(byte_arr, format='PNG')\n",
        "    byte_arr = byte_arr.getvalue()\n",
        "    return str(base64.b64encode(byte_arr).decode('utf-8'))\n",
        "\n",
        "def captioner(image):\n",
        "    get_completion = pipeline(\"image-to-text\",model=\"Salesforce/blip-image-captioning-base\")\n",
        "    base64_image = image_to_base64_str(image)\n",
        "    result = get_completion(base64_image)\n",
        "    return result[0]['generated_text']\n",
        "\n",
        "def generate(prompt):\n",
        "    diff_pipeline = DiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\")\n",
        "    diff_pipeline.to(\"cuda\")  # we want to use GPU!\n",
        "    return diff_pipeline(prompt).images[0]"
      ],
      "metadata": {
        "id": "OUtuXv_GqHZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### First attempt, just captioning"
      ],
      "metadata": {
        "id": "2FxnfxfAsVR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Describe-and-Generate game ðŸ–ï¸\")\n",
        "    image_upload = gr.Image(label=\"Your first image\",type=\"pil\")\n",
        "    btn_caption = gr.Button(\"Generate caption\")\n",
        "    caption = gr.Textbox(label=\"Generated caption\")\n",
        "\n",
        "    btn_caption.click(fn=captioner, inputs=[image_upload], outputs=[caption])\n",
        "\n",
        "gr.close_all()\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "EfTQk-YwsJ4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Let's add generation"
      ],
      "metadata": {
        "id": "rMQyHUVEsuTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Describe-and-Generate game ðŸ–ï¸\")\n",
        "    image_upload = gr.Image(label=\"Your first image\",type=\"pil\")\n",
        "    btn_caption = gr.Button(\"Generate caption\")\n",
        "    caption = gr.Textbox(label=\"Generated caption\")\n",
        "    btn_image = gr.Button(\"Generate image\")\n",
        "    image_output = gr.Image(label=\"Generated Image\")\n",
        "    btn_caption.click(fn=captioner, inputs=[image_upload], outputs=[caption])\n",
        "    btn_image.click(fn=generate, inputs=[caption], outputs=[image_output])\n",
        "\n",
        "gr.close_all()\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "ge9jBzENsxog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Doing it all at once!"
      ],
      "metadata": {
        "id": "6erVdS5MtSwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def caption_and_generate(image):\n",
        "    caption = captioner(image)\n",
        "    image = generate(caption)\n",
        "    return [caption, image]"
      ],
      "metadata": {
        "id": "JBTCtkWrtbRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# Describe-and-Generate game ðŸ–ï¸\")\n",
        "    image_upload = gr.Image(label=\"Your first image\",type=\"pil\")\n",
        "    btn_all = gr.Button(\"Caption and generate\")\n",
        "    caption = gr.Textbox(label=\"Generated caption\")\n",
        "    image_output = gr.Image(label=\"Generated Image\")\n",
        "\n",
        "    btn_all.click(fn=caption_and_generate, inputs=[image_upload], outputs=[caption, image_output])\n",
        "\n",
        "gr.close_all()\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "ceZiB6_VtYNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### L5: Chat with any LLM!"
      ],
      "metadata": {
        "id": "MT3CCunTuGG-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unfortunately the `falcon-40b-instruct` requires too much memory and cannot be loaded into Google Colab. The Hugging Face Inference API cannot be used either. It is possible though to use [Inference Endpoints](https://huggingface.co/inference-endpoints) as is done in the course, but that service is not for free. Watch the course video to get a better idea how a chatbot is developed!"
      ],
      "metadata": {
        "id": "QmzkYjEa-EMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt Engineering"
      ],
      "metadata": {
        "id": "96a6B7m1tpHu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt engineering is a technique used when interacting with large language models (LLMs) like GPT-3.5. It involves crafting well-designed input prompts to guide the model towards generating desired outputs. The goal of prompt engineering is to optimize the communication between a user and the language model, eliciting responses that align with the user's intent or specific requirements.\n",
        "\n",
        "Check out the following free online course from deeplearning.ai to learn more about prompt engineering:"
      ],
      "metadata": {
        "id": "EKF5uPbtvSyv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- https://learn.deeplearning.ai/chatgpt-prompt-eng"
      ],
      "metadata": {
        "id": "KKrWfFOmtsWF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "uNVzySx9xEoB"
      }
    }
  ]
}